{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kenwaldek/Whisper/blob/main/YT_dwld_search_date_upload_V3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNOHV3rsmXox",
        "outputId": "a3d4a7c5-b74b-40ce-a926-82edde0f33a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting yt-dlp\n",
            "  Downloading yt_dlp-2024.11.18-py3-none-any.whl.metadata (172 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/172.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.1/172.1 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yt_dlp-2024.11.18-py3-none-any.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: yt-dlp\n",
            "Successfully installed yt-dlp-2024.11.18\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (2.151.0)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (0.22.0)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (2.27.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (0.2.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (2.19.2)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (4.1.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.66.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (4.25.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.25.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (4.9)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client) (3.2.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2024.8.30)\n",
            "Searching YouTube for latest videos: 'rick rule'...\n",
            "Found videos:\n",
            "2024-11-18 - New Trump Era, 10 Commodities Analysis, Enriched Uranium Export Ban to the U.S - Rick Rule (https://www.youtube.com/watch?v=i8HPbeWcLH0)\n",
            "2024-11-18 - Rick Rule&#39;s Wisdom &amp; a New Copper Porphyry Exploration Program in BC (https://www.youtube.com/watch?v=DzYIJgFNkTE)\n",
            "2024-11-18 - Rick Rule: &quot;Everyone Who Owns Gold Needs To Know It&#39;s Going To $10.000&quot; 2025 Prediction (https://www.youtube.com/watch?v=KA5Kmqhqzpw)\n",
            "\n",
            "Downloading audio...\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=i8HPbeWcLH0\n",
            "[youtube] i8HPbeWcLH0: Downloading webpage\n",
            "[youtube] i8HPbeWcLH0: Downloading ios player API JSON\n",
            "[youtube] i8HPbeWcLH0: Downloading mweb player API JSON\n",
            "[youtube] i8HPbeWcLH0: Downloading player 5f315c3d\n",
            "[youtube] i8HPbeWcLH0: Downloading m3u8 information\n",
            "[info] i8HPbeWcLH0: Downloading 1 format(s): 251\n",
            "[download] Destination: ./Audio/2024-11-18 - New Trump Era, 10 Commodities Analysis, Enriched Uranium Export Ban to the U.S - Rick Rule.webm\n",
            "[download] 100% of   43.89MiB in 00:00:00 at 93.90MiB/s  \n",
            "[ExtractAudio] Destination: ./Audio/2024-11-18 - New Trump Era, 10 Commodities Analysis, Enriched Uranium Export Ban to the U.S - Rick Rule.mp3\n",
            "Deleting original file ./Audio/2024-11-18 - New Trump Era, 10 Commodities Analysis, Enriched Uranium Export Ban to the U.S - Rick Rule.webm (pass -k to keep)\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=DzYIJgFNkTE\n",
            "[youtube] DzYIJgFNkTE: Downloading webpage\n",
            "[youtube] DzYIJgFNkTE: Downloading ios player API JSON\n",
            "[youtube] DzYIJgFNkTE: Downloading mweb player API JSON\n",
            "[youtube] DzYIJgFNkTE: Downloading player 2d24ba15\n",
            "[youtube] DzYIJgFNkTE: Downloading m3u8 information\n",
            "[info] DzYIJgFNkTE: Downloading 1 format(s): 251\n",
            "[download] Destination: ./Audio/2024-11-18 - Rick Rule&#39;s Wisdom &amp; a New Copper Porphyry Exploration Program in BC.webm\n",
            "[download] 100% of   71.75MiB in 00:00:08 at 8.08MiB/s   \n",
            "[ExtractAudio] Destination: ./Audio/2024-11-18 - Rick Rule&#39;s Wisdom &amp; a New Copper Porphyry Exploration Program in BC.mp3\n",
            "Deleting original file ./Audio/2024-11-18 - Rick Rule&#39;s Wisdom &amp; a New Copper Porphyry Exploration Program in BC.webm (pass -k to keep)\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=KA5Kmqhqzpw\n",
            "[youtube] KA5Kmqhqzpw: Downloading webpage\n",
            "[youtube] KA5Kmqhqzpw: Downloading ios player API JSON\n",
            "[youtube] KA5Kmqhqzpw: Downloading mweb player API JSON\n",
            "[youtube] KA5Kmqhqzpw: Downloading m3u8 information\n",
            "[info] KA5Kmqhqzpw: Downloading 1 format(s): 251\n",
            "[download] Destination: ./Audio/2024-11-18 - Rick Rule: &quot;Everyone Who Owns Gold Needs To Know It&#39;s Going To $10.000&quot; 2025 Prediction.webm\n",
            "[download] 100% of   18.76MiB in 00:00:02 at 9.19MiB/s   \n",
            "[ExtractAudio] Destination: ./Audio/2024-11-18 - Rick Rule: &quot;Everyone Who Owns Gold Needs To Know It&#39;s Going To $10.000&quot; 2025 Prediction.mp3\n",
            "Deleting original file ./Audio/2024-11-18 - Rick Rule: &quot;Everyone Who Owns Gold Needs To Know It&#39;s Going To $10.000&quot; 2025 Prediction.webm (pass -k to keep)\n",
            "Audio files downloaded to: ./Audio\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Install necessary dependencies\n",
        "!pip install yt-dlp\n",
        "!pip install google-api-python-client\n",
        "\n",
        "# Cell 2: Import libraries\n",
        "import os\n",
        "from yt_dlp import YoutubeDL\n",
        "from googleapiclient.discovery import build\n",
        "\n",
        "# Cell 3: Function to search YouTube using the YouTube Data API\n",
        "def search_youtube_videos(query, api_key, max_results=10):\n",
        "    youtube = build('youtube', 'v3', developerKey=api_key)\n",
        "    request = youtube.search().list(\n",
        "        q=query,\n",
        "        part='snippet',\n",
        "        type='video',\n",
        "        order='date',\n",
        "        maxResults=max_results\n",
        "    )\n",
        "    response = request.execute()\n",
        "\n",
        "    video_data = [\n",
        "        {\n",
        "            \"url\": f\"https://www.youtube.com/watch?v={item['id']['videoId']}\",\n",
        "            \"title\": item['snippet']['title'],\n",
        "            \"published_at\": item['snippet']['publishedAt'][:10]  # Extract date (YYYY-MM-DD)\n",
        "        }\n",
        "        for item in response['items']\n",
        "    ]\n",
        "\n",
        "    return video_data\n",
        "\n",
        "# Cell 4: Function to download audio using yt-dlp\n",
        "def download_audio(video_data, download_folder):\n",
        "    if not os.path.exists(download_folder):\n",
        "        os.makedirs(download_folder)\n",
        "\n",
        "    for video in video_data:\n",
        "        ydl_opts = {\n",
        "            'outtmpl': os.path.join(download_folder, f\"{video['published_at']} - {video['title']}.%(ext)s\"),\n",
        "            'format': 'bestaudio/best',\n",
        "            'postprocessors': [{\n",
        "                'key': 'FFmpegExtractAudio',\n",
        "                'preferredcodec': 'mp3',\n",
        "                'preferredquality': '192',\n",
        "            }],\n",
        "            'noplaylist': True\n",
        "        }\n",
        "\n",
        "        with YoutubeDL(ydl_opts) as ydl:\n",
        "            ydl.download([video[\"url\"]])\n",
        "\n",
        "# Cell 5: Main function to perform the search and download\n",
        "def main():\n",
        "    api_key = \"AIzaSyDp_XV5lBEeJNz0j6sR_BDR6q7aFH1al_s\"  # Replace with your API key\n",
        "    search_query = \"rick rule\"\n",
        "    max_videos = 3\n",
        "    download_folder = \"./Audio\"\n",
        "\n",
        "    print(f\"Searching YouTube for latest videos: '{search_query}'...\")\n",
        "    video_data = search_youtube_videos(search_query, api_key, max_results=max_videos)\n",
        "\n",
        "    print(\"Found videos:\")\n",
        "    for video in video_data:\n",
        "        print(f\"{video['published_at']} - {video['title']} ({video['url']})\")\n",
        "\n",
        "    print(\"\\nDownloading audio...\")\n",
        "    download_audio(video_data, download_folder)\n",
        "    print(f\"Audio files downloaded to: {download_folder}\")\n",
        "\n",
        "# Cell 6: Execute the script\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "6N-jEKGzY8ap",
        "outputId": "1c6d02ce-8ea0-4899-b8ef-db7c4e1ce788"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting in 10 seconds...\n",
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-d_ngx817\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-d_ngx817\n",
            "  Resolved https://github.com/openai/whisper.git to commit 173ff7dd1d9fb1c4fddea0d41d704cfefeb8908c\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (2.5.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (4.66.6)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (10.5.0)\n",
            "Collecting tiktoken (from openai-whisper==20240930)\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting triton>=2.0.0 (from openai-whisper==20240930)\n",
            "  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton>=2.0.0->openai-whisper==20240930) (3.16.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20240930) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20240930) (2024.9.11)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20240930) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->openai-whisper==20240930) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20240930) (3.0.2)\n",
            "Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803557 sha256=0c7a9a6234ceb6601bbbdf953b7263d0e29cb994db253f5d4154f89c3293c63f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-t5il_eej/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: triton, tiktoken, openai-whisper\n",
            "Successfully installed openai-whisper-20240930 tiktoken-0.8.0 triton-3.1.0\n",
            "Collecting ffmpeg\n",
            "  Downloading ffmpeg-1.4.tar.gz (5.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: ffmpeg\n",
            "  Building wheel for ffmpeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6082 sha256=be522e238143bfcd2c6a74ecf423f7cb0ce843bc003993d378cceadfe5b0b0e0\n",
            "  Stored in directory: /root/.cache/pip/wheels/8e/7a/69/cd6aeb83b126a7f04cbe7c9d929028dc52a6e7d525ff56003a\n",
            "Successfully built ffmpeg\n",
            "Installing collected packages: ffmpeg\n",
            "Successfully installed ffmpeg-1.4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|█████████████████████████████████████| 1.42G/1.42G [00:18<00:00, 81.1MiB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transcribing 2024-11-18 - New Trump Era, 10 Commodities Analysis, Enriched Uranium Export Ban to the U.S - Rick Rule.mp3...\n",
            "Saved transcription to: ./TXT/2024-11-18 - New Trump Era, 10 Commodities Analysis, Enriched Uranium Export Ban to the U.S - Rick Rule.txt\n",
            "Transcribing 2024-11-18 - Rick Rule&#39;s Wisdom &amp; a New Copper Porphyry Exploration Program in BC.mp3...\n",
            "Saved transcription to: ./TXT/2024-11-18 - Rick Rule&#39;s Wisdom &amp; a New Copper Porphyry Exploration Program in BC.txt\n",
            "Transcribing 2024-11-18 - Rick Rule: &quot;Everyone Who Owns Gold Needs To Know It&#39;s Going To $10.000&quot; 2025 Prediction.mp3...\n",
            "Saved transcription to: ./TXT/2024-11-18 - Rick Rule: &quot;Everyone Who Owns Gold Needs To Know It&#39;s Going To $10.000&quot; 2025 Prediction.txt\n",
            "Transcriptions saved in: ./TXT\n"
          ]
        }
      ],
      "source": [
        "import time  # Import the time module for delay\n",
        "\n",
        "# Delay execution by 10 seconds\n",
        "print(\"Starting in 10 seconds...\")\n",
        "time.sleep(10)\n",
        "\n",
        "# Install Whisper from the specified repository\n",
        "!pip install git+https://github.com/openai/whisper.git\n",
        "!pip install ffmpeg  # Ensure ffmpeg is installed for audio processing\n",
        "\n",
        "# Import required libraries\n",
        "import os\n",
        "import whisper\n",
        "\n",
        "# Define input and output folders\n",
        "audio_folder = \"./Audio\"\n",
        "txt_folder = \"./TXT\"\n",
        "\n",
        "# Create the TXT folder if it doesn't exist\n",
        "if not os.path.exists(txt_folder):\n",
        "    os.makedirs(txt_folder)\n",
        "\n",
        "# Load Whisper medium model\n",
        "model = whisper.load_model(\"medium\")  # Use the medium model for more accuracy\n",
        "\n",
        "# Function to transcribe audio files and save as .txt in English\n",
        "def transcribe_audio_files(audio_folder, txt_folder):\n",
        "    for audio_file in os.listdir(audio_folder):\n",
        "        if audio_file.endswith(\".mp3\"):\n",
        "            audio_path = os.path.join(audio_folder, audio_file)\n",
        "            output_txt_path = os.path.join(txt_folder, f\"{os.path.splitext(audio_file)[0]}.txt\")\n",
        "\n",
        "            print(f\"Transcribing {audio_file}...\")\n",
        "\n",
        "            # Transcribe and translate to English\n",
        "            result = model.transcribe(audio_path, language=None, task=\"translate\")\n",
        "\n",
        "            # Save the transcription to a .txt file\n",
        "            with open(output_txt_path, \"w\", encoding=\"utf-8\") as txt_file:\n",
        "                txt_file.write(result[\"text\"])\n",
        "\n",
        "            print(f\"Saved transcription to: {output_txt_path}\")\n",
        "\n",
        "# Transcribe all audio files\n",
        "transcribe_audio_files(audio_folder, txt_folder)\n",
        "\n",
        "print(f\"Transcriptions saved in: {txt_folder}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlFMtMf1agY0",
        "outputId": "8541c979-d883-457a-dcf7-4e11178cabf1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Waiting for 10 seconds to ensure all files are ready...\n",
            "Processed and saved: ./TXT_mod/2024-11-18 - New Trump Era, 10 Commodities Analysis, Enriched Uranium Export Ban to the U.S - Rick Rule.txt\n",
            "Processed and saved: ./TXT_mod/2024-11-18 - Rick Rule&#39;s Wisdom &amp; a New Copper Porphyry Exploration Program in BC.txt\n",
            "Processed and saved: ./TXT_mod/2024-11-18 - Rick Rule: &quot;Everyone Who Owns Gold Needs To Know It&#39;s Going To $10.000&quot; 2025 Prediction.txt\n",
            "All files have been processed and saved in: ./TXT_mod\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "# Delay execution by 10 seconds\n",
        "print(\"Waiting for 10 seconds to ensure all files are ready...\")\n",
        "time.sleep(10)\n",
        "\n",
        "# Define the input and output folders\n",
        "txt_folder = \"./TXT\"\n",
        "txt_mod_folder = \"./TXT_mod\"\n",
        "\n",
        "# Create the TXT_mod folder if it doesn't exist\n",
        "if not os.path.exists(txt_mod_folder):\n",
        "    os.makedirs(txt_mod_folder)\n",
        "\n",
        "# Process each .txt file in the TXT folder\n",
        "for txt_file in os.listdir(txt_folder):\n",
        "    if txt_file.endswith(\".txt\"):\n",
        "        input_txt_path = os.path.join(txt_folder, txt_file)\n",
        "        output_txt_path = os.path.join(txt_mod_folder, txt_file)\n",
        "\n",
        "        # Read the contents of the .txt file\n",
        "        with open(input_txt_path, \"r\", encoding=\"utf-8\") as file:\n",
        "            content = file.read()\n",
        "\n",
        "        # Add the filename (without extension) as the title at the top\n",
        "        title = os.path.splitext(txt_file)[0]  # Get filename without extension\n",
        "        modified_content = f\"{title}\\n\\n{content}\"\n",
        "\n",
        "        # Save the modified content to the new .txt file in TXT_mod\n",
        "        with open(output_txt_path, \"w\", encoding=\"utf-8\") as file:\n",
        "            file.write(modified_content)\n",
        "\n",
        "        print(f\"Processed and saved: {output_txt_path}\")\n",
        "\n",
        "print(f\"All files have been processed and saved in: {txt_mod_folder}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rz0rpvaGkpAs"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import zipfile\n",
        "from datetime import datetime\n",
        "\n",
        "# Delay execution by 4 seconds to ensure previous operations are complete\n",
        "print(\"Waiting for 4 seconds to ensure previous operations are complete...\")\n",
        "time.sleep(4)\n",
        "\n",
        "# Define folders\n",
        "audio_folder = \"./Audio\"\n",
        "txt_mod_folder = \"./TXT_mod\"\n",
        "\n",
        "# Ensure the folders exist before proceeding\n",
        "if not os.path.exists(audio_folder):\n",
        "    print(f\"Folder '{audio_folder}' does not exist.\")\n",
        "    exit()\n",
        "if not os.path.exists(txt_mod_folder):\n",
        "    print(f\"Folder '{txt_mod_folder}' does not exist.\")\n",
        "    exit()\n",
        "\n",
        "# Get current date in yyyy-mm-dd format\n",
        "current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
        "\n",
        "# Define the search string used (replace 'Sewer data' with the actual search term)\n",
        "search_string = \"Sewer data\"\n",
        "formatted_search_string = search_string.replace(\" \", \"_\")\n",
        "\n",
        "# Function to compress a single file\n",
        "def compress_file(file_path, output_zip):\n",
        "    with zipfile.ZipFile(output_zip, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "        arcname = os.path.basename(file_path)  # Store only the file name in the ZIP\n",
        "        zipf.write(file_path, arcname)\n",
        "\n",
        "# Compress each audio file in the Audio folder\n",
        "for audio_file in os.listdir(audio_folder):\n",
        "    if audio_file.endswith(\".mp3\"):\n",
        "        audio_file_path = os.path.join(audio_folder, audio_file)\n",
        "        audio_zip_filename = f\"{os.path.splitext(audio_file)[0]}.zip\"  # Only the file name without extensions\n",
        "        compress_file(audio_file_path, audio_zip_filename)\n",
        "        print(f\"Compressed '{audio_file}' into '{audio_zip_filename}'.\")\n",
        "\n",
        "# Compress the entire TXT_mod folder\n",
        "txt_mod_zip_filename = f\"{current_date}_{formatted_search_string}_TXT_mod.zip\"\n",
        "\n",
        "def compress_folder(folder_path, output_zip):\n",
        "    with zipfile.ZipFile(output_zip, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "        for root, _, files in os.walk(folder_path):\n",
        "            for file in files:\n",
        "                file_path = os.path.join(root, file)\n",
        "                arcname = os.path.relpath(file_path, start=os.path.dirname(folder_path))\n",
        "                zipf.write(file_path, arcname)\n",
        "\n",
        "compress_folder(txt_mod_folder, txt_mod_zip_filename)\n",
        "print(f\"Compressed '{txt_mod_folder}' into '{txt_mod_zip_filename}'.\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "mount_file_id": "11SpaC5YCgPfKULP95icjYOTJ2hokqthe",
      "authorship_tag": "ABX9TyPdRpexIf56/Nlx2z3YKu0t",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}